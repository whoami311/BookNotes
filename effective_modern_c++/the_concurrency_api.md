# 并发 API

C++11 的伟大成功之一是将并发整合到语言和库中。熟悉其他线程 API（比如 pthreads 或者 Windows threads）的开发者有时可能会对 C++ 提供的斯巴达式（译者注：应该是简陋和严谨的意思）功能集感到惊讶，这是因为 C++ 对于并发的大量支持是在对编译器作者约束的层面。由此产生的语言保证意味着在 C++ 的历史中，开发者首次通过标准库可以写出跨平台的多线程程序。这为构建表达库奠定了坚实的基础，标准库并发组件（任务 *tasks*，期望 *futures*，线程 *threads*，互斥 *mutexes*，条件变量 *condition variables*，原子对象 *atomic objects* 等）仅仅是成为并发软件开发者丰富工具集的基础。

在接下来的条款中，记住标准库有两个future的模板：`std::future` 和 `std::shared_future`。在许多情况下，区别不重要，所以我们经常简单的混于一谈为 *futures*。

## Item 35：优先考虑基于任务的编程而非基于线程的编程

如果开发者想要异步执行函数，通常有两种方式。其一是通过创建 `std::thread` 执行，这是应用了**基于线程**（*thread-based*）的方式。

其二是将函数传递给 `std::async`，一种**基于任务**（*task-based*）的策略。这种方式中，传递给 `std::async` 的函数对象被称为一个**任务**（task）。

基于任务的方法通常比基于线程的方法更优，原因之一是基于任务的方法代码量更少。假设调用函数的代码对于其提供的返回值是有需求的。基于线程的方法对此无能为力，而基于任务的方法就简单了，因为 `std::async` 返回的 future 提供了 `get` 函数（从而可以获取返回值）。如果执行函数发生了异常，`get` 函数就显得更为重要，因为 `get` 函数可以提供抛出异常的访问，而基于线程的方法，如果执行函数抛出了异常，程序会直接终止（通过调用 `std::terminate`）。

基于线程与基于任务最根本的区别在于，基于任务的抽象层次更高。基于任务的方式使得开发者从线程管理的细节中解放出来，对此在 C++ 并发软件中总结了“thread”的三种含义：

- **硬件线程**（hardware threads）是真实执行计算的线程。现代计算机体系结构为每个 CPU 核心提供一个或者多个硬件线程。
- **软件线程**（software threads）（也被称为系统线程（OS threads、system threads））是操作系统（假设有一个操作系统。有些嵌入式系统没有。）管理的在硬件线程上执行的线程。通常可以存在比硬件线程更多数量的软件线程，因为当软件线程被阻塞的时候（比如 I/O、同步锁或者条件变量），操作系统可以调度其他未阻塞的软件线程执行提供吞吐量。
- `std::thread` 是 C++ 执行过程的对象，并作为软件线程的句柄（handle）。有些 `std::thread` 对象代表“空”句柄，即没有对应软件线程，因为它们处在默认构造状态（即没有函数要执行）；有些被移动走（移动到的 `std::thread` 就作为这个软件线程的句柄）；有些被 `join`（它们要运行的函数已经运行完）；有些被 `detach`（它们和对应的软件线程之间的连接关系被打断）。

软件线程是有限的资源。如果开发者试图创建大于系统支持的线程数量，会抛出 `std::system_error` 异常。

设计良好的软件必须能有效地处理这种可能性，但是怎样做？一种方法是在当前线程执行 `doAsyncWork`，但是这可能会导致负载不均，而且如果当前线程是 GUI 线程，可能会导致响应时间过长的问题。另一种方法是等待某些当前运行的软件线程结束之后再创建新的 `std::thread`，但是仍然有可能当前运行的线程在等待 `doAsyncWork` 的动作（例如产生一个结果或者报告一个条件变量）。

即使没有超出软件线程的限额，仍然可能会遇到**资源超额**（*oversubscription*）的麻烦。这是一种当前准备运行的（即未阻塞的）软件线程大于硬件线程的数量的情况。情况发生时，线程调度器（操作系统的典型部分）会将软件线程时间切片，分配到硬件上。当一个软件线程的时间片执行结束，会让给另一个软件线程，此时发生上下文切换。软件线程的上下文切换会增加系统的软件线程管理开销，当软件线程安排到与上次时间片运行时不同的硬件线程上，这个开销会更高。这种情况下，（1）CPU缓存对这个软件线程很冷淡（即几乎没有什么数据，也没有有用的操作指南）；（2）“新”软件线程的缓存数据会“污染”“旧”线程的数据，旧线程之前运行在这个核心上，而且还有可能再次在这里运行。

避免资源超额很困难，因为软件线程之于硬件线程的最佳比例取决于软件线程的执行频率，那是动态改变的，比如一个程序从 IO 密集型变成计算密集型，执行频率是会改变的。而且比例还依赖上下文切换的开销以及软件线程对于 CPU 缓存的使用效率。此外，硬件线程的数量和 CPU 缓存的细节（比如缓存多大，相应速度多少）取决于机器的体系结构，即使经过调校，在某一种机器平台避免了资源超额（而仍然保持硬件的繁忙状态），换一个其他类型的机器这个调校并不能提供较好效果的保证。

如果你把这些问题推给另一个人做，你就会变得很轻松，而使用 `std::async` 就做了这件事。

这种调用方式将线程管理的职责转交给 C++ 标准库的开发者。举个例子，这种调用方式会减少抛出资源超额异常的可能性，因为这个调用可能不会开启一个新的线程。你会想：“怎么可能？如果我要求比系统可以提供的更多的软件线程，创建 `std::thread` 和调用 `std::async` 为什么会有区别？”确实有区别，因为以这种形式调用（即使用默认启动策略——见 Item 36）时，`std::async` 不保证会创建新的软件线程。然而，他们允许通过调度器来将特定函数（本例中为 `doAsyncWork`）运行在等待此函数结果的线程上（即在对返回值调用 `get` 或者 `wait` 的线程上），合理的调度器在系统资源超额或者线程耗尽时就会利用这个自由度。

如果考虑自己实现“在等待结果的线程上运行输出结果的函数”，之前提到了可能引出负载不均衡的问题，这问题不那么容易解决，因为应该是 `std::async` 和运行时的调度程序来解决这个问题而不是你。遇到负载不均衡问题时，对机器内发生的事情，运行时调度程序比你有更全面的了解，因为它管理的是所有执行过程，而不仅仅个别开发者运行的代码。

有了 `std::async`，GUI 线程中响应变慢仍然是个问题，因为调度器并不知道你的哪个线程有高响应要求。这种情况下，你会想通过向 `std::async` 传递 `std::launch::async` 启动策略来保证想运行函数在不同的线程上执行（见 Item 36）。

最前沿的线程调度器使用系统级线程池（*thread pool*）来避免资源超额的问题，并且通过工作窃取算法（*work-stealing algorithm*）来提升了跨硬件核心的负载均衡。C++ 标准实际上并不要求使用线程池或者工作窃取，实际上 C++11 并发规范的某些技术层面使得实现这些技术的难度可能比想象中更有挑战。不过，库开发者在标准库实现中采用了这些技术，也有理由期待这个领域会有更多进展。如果你当前的并发编程采用基于任务的方式，在这些技术发展中你会持续获得回报。相反如果你直接使用 `std::thread` 编程，处理线程耗尽、资源超额、负载均衡问题的责任就压在了你身上，更不用说你对这些问题的解决方法与同机器上其他程序采用的解决方案配合得好不好了。

对比基于线程的编程方式，基于任务的设计为开发者避免了手动线程管理的痛苦，并且自然提供了一种获取异步执行程序的结果（即返回值或者异常）的方式。当然，仍然存在一些场景直接使用 `std::thread` 会更有优势：

- **你需要访问非常基础的线程 API**。C++ 并发 API 通常是通过操作系统提供的系统级 API（pthreads 或者 Windows threads）来实现的，系统级 API 通常会提供更加灵活的操作方式（举个例子，C++ 没有线程优先级和亲和性的概念）。为了提供对底层系统级线程 API 的访问，`std::thread` 对象提供了 `native_handle` 的成员函数，而 `std::future`（即 `std::async` 返回的东西）没有这种能力。
- **你需要且能够优化应用的线程使用**。举个例子，你要开发一款已知执行概况的服务器软件，部署在有固定硬件特性的机器上，作为唯一的关键进程。
- **你需要实现 C++ 并发 API 之外的线程技术**，比如，C++ 实现中未支持的平台的线程池。

这些都是在应用开发中并不常见的例子，大多数情况，开发者应该优先采用基于任务的编程方式。

**请记住：**

- `std::thread` API 不能直接访问异步执行的结果，如果执行函数有异常抛出，代码会终止执行。
- 基于线程的编程方式需要手动的线程耗尽、资源超额、负责均衡、平台适配性管理。
- 通过带有默认启动策略的 `std::async` 进行基于任务的编程方式会解决大部分问题。

## Item 36：如果有异步的必要请指定std::launch::async

TODO

## Item 37：从各个方面使得 `std::thread` unjoinable

每个 `std::thread` 对象处于两个状态之一：**可结合的**（joinable）或者**不可结合的**（unjoinable）。可结合状态的 `std::thread` 对应于正在运行或者可能要运行的异步执行线程。

不可结合的 `std::thread` 正如所期待：一个不是可结合状态的 `std::thread`。不可结合的 `std::thread` 对象包括：

- **默认构造的**`std::thread`。这种 `std::thread` 没有函数执行，因此没有对应到底层执行线程上。
- **已经被移动走的**`std::thread` 对象。移动的结果就是一个 `std::thread` 原来对应的执行线程现在对应于另一个 `std::thread`。
- **已经被 `join` 的**`std::thread`。在 `join` 之后，`std::thread` 不再对应于已经运行完了的执行线程。
- **已经被 `detach` 的** `std::thread` 。`detach` 断开了 `std::thread` 对象与执行线程之间的连接。

`std::thread` 的可结合性如此重要的原因之一就是当可结合的线程的析构函数被调用，程序执行会终止。

为什么`std::thread` 析构的行为是这样的，那是因为另外两种显而易见的方式更糟：

- **隐式 `join`**。这种情况下，`std::thread` 的析构函数将等待其底层的异步执行线程完成。这听起来是合理的，但是可能会导致难以追踪的异常表现。
- **隐式 `detach`**。这种情况下，`std::thread` 析构函数会分离 `std::thread` 与其底层的线程。底层线程继续运行。听起来比 `join` 的方式好，但是可能导致更严重的调试问题。

标准委员会认为，销毁可结合的线程如此可怕以至于实际上禁止了它（规定销毁可结合的线程导致程序终止）。

这使你有责任确保使用 `std::thread` 对象时，在所有的路径上超出定义所在的作用域时都是不可结合的。

每当你想在执行跳至块之外的每条路径执行某种操作，最通用的方式就是将该操作放入局部对象的析构函数中。这些对象称为 **RAII 对象**（RAII objects），从 **RAII 类**中实例化。（RAII 全称为 “Resource Acquisition Is Initialization”（资源获得即初始化），尽管技术关键点在析构上而不是实例化上）。但是标准库没有 `std::thread` 的 RAII 类，可能是因为标准委员会拒绝将 `join` 和 `detach` 作为默认选项，不知道应该怎么样完成 RAII。

```c++
class ThreadRAII {
public:
    enum class DtorAction { join, detach };     //enum class的信息见条款10
    
    ThreadRAII(std::thread&& t, DtorAction a)   //析构函数中对t实行a动作
    : action(a), t(std::move(t)) {}

    ~ThreadRAII()
    {                                           //可结合性测试见下
        if (t.joinable()) {
            if (action == DtorAction::join) {
                t.join();
            } else {
                t.detach();
            }
        }
    }

    ThreadRAII(ThreadRAII&&) = default;             //支持移动
    ThreadRAII& operator=(ThreadRAII&&) = default;

    std::thread& get() { return t; }            //见下

private:
    DtorAction action;
    std::thread t;
};
```

这种情况下，我们选择在 `ThreadRAII` 的析构函数对异步执行的线程进行 `join`，因为在先前分析中，`detach` 可能导致噩梦般的调试过程。我们之前也分析了 `join` 可能会导致表现异常（坦率说，也可能调试困难），但是在未定义行为（`detach` 导致），程序终止（使用原生 `std::thread` 导致），或者表现异常之间选择一个后果，可能表现异常是最好的那个。

**请记住：**

- 在所有路径上保证 `thread` 最终是不可结合的。
- 析构时 `join` 会导致难以调试的表现异常问题。
- 析构时 `detach` 会导致难以调试的未定义行为。
- 声明类数据成员时，最后声明 `std::thread` 对象。

## Item 38：关注不同线程句柄的析构行为

TODO

## Item 39：

TODO

## Item 40：对于并发使用 `std::atomic`，对于特殊内存使用 `volatile`

可怜的 `volatile`。如此令人迷惑。本不应该出现在本章节，因为它跟并发编程没有关系。但是在其他编程语言中（比如，Java 和 C#），`volatile`是有并发含义的，即使在 C++ 中，有些编译器在实现时也将并发的某种含义加入到了 `volatile` 关键字中（但仅仅是在用那些编译器时）。因此在此值得讨论下关于 `volatile` 关键字的含义以消除异议。

开发者有时会与 `volatile` 混淆的特性——本来应该属于本章的那个特性——是 `std::atomic` 模板。这种模板的实例化提供了一种在其他线程看来操作是原子性的的保证（译注：即某些操作是像原子一样的不可分割。）。一旦 `std::atomic` 对象被构建，在其上的操作表现得像操作是在互斥锁保护的关键区内，但是通常这些操作是使用特定的机器指令实现，这比锁的实现更高效。

读-改-写（read-modify-write，RMW）操作，它们整体作为原子执行。这是 `std::atomic` 类型的最优的特性之一：一旦 `std::atomic` 对象被构建，所有成员函数，包括 RMW 操作，从其他线程来看都是原子性的。

```c++
std::atomic<bool> valVailable(false); 
auto imptValue = computeImportantValue();   //计算值
valAvailable = true;                        //告诉另一个任务，值可用了
```

人类读这份代码，能看到在 `valAvailabl` e赋值之前对 `imptValue` 赋值很关键，但是所有编译器看到的是给相互独立的变量的一对赋值操作。通常来说，编译器会被允许重排这对没有关联的操作。

即使编译器没有重排顺序，底层硬件也可能重排（或者可能使它看起来运行在其他核心上），因为有时这样代码执行更快。

然而，`std::atomic` 会限制这种重排序，并且这样的限制之一是，在源代码中，对 `std::atomic` 变量写之前不会有任何操作（或者操作发生在其他核心上）。（这只在 `std::atomics` 使用**顺序一致性**（sequential consistency）时成立，对于使用在本书中展示的语法的 `std::atomic` 对象，这也是默认的和唯一的一致性模型。C++11 也支持带有更灵活的代码重排规则的一致性模型。这样的**弱**（weak）（亦称**松散的**，relaxed）模型使构建一些软件在某些硬件构架上运行的更快成为可能，但是使用这样的模型产生的软件**更加**难改正、理解、维护。在使用松散原子性的代码中微小的错误很常见，即使专家也会出错，所以应当尽可能坚持顺序一致性。）

这两个问题——不保证操作的原子性以及对代码重排顺序没有足够限制——解释了为什么 `volatile` 在多线程编程中没用，但是没有解释它应该用在哪。简而言之，它是用来告诉编译器，它们处理的内存有不正常的表现。

```c++
int x;

auto y = x;                             //读x
y = x;                                  //再次读x
x = 10;                                 //写x
x = 20;                                 //再次写x
```

可能你会想谁会写这种重复读写的代码（技术上称为**冗余访问**（redundant loads）和**无用存储**（dead stores）），答案是开发者不会直接写——至少我们不希望开发者这样写。但是在编译器拿到看起来合理的代码，执行了模板实例化，内联和一系列重排序优化之后，结果会出现冗余访问和无用存储，所以编译器需要摆脱这样的情况并不少见。

这种优化仅仅在内存表现正常时有效。“特殊”的内存不行。最常见的“特殊”内存是用来做内存映射 I/O 的内存。这种内存实际上是与外围设备（比如外部传感器或者显示器，打印机，网络端口）通信，而不是读写通常的内存（比如 RAM ）。

`volatile` 是告诉编译器我们正在处理特殊内存。意味着告诉编译器“不要对这块内存执行任何优化”。所以如果 `x` 对应于特殊内存，应该声明为 `volatile`。

```c++
volatile int x;

auto y = x;                             //读x
y = x;                                  //再次读x（不会被优化掉）

x = 10;                                 //写x（不会被优化掉）
x = 20;                                 //再次写x
```

突击测试！在最后一段代码中，`y` 是什么类型：`int` 还是 `volatile int`？（`y` 的类型使用 `auto` 类型推导，所以使用 Item 2 中的规则。规则上说非引用非指针类型的声明（就是 `y` 的情况），`const` 和 `volatile` 限定符被拿掉。`y` 的类型因此仅仅是 `int`。这意味着对 `y` 的冗余读取和写入可以被消除。在例子中，编译器必须执行对 `y` 的初始化和赋值两个语句，因为 `x` 是 `volatile` 的，所以第二次对 `x` 的读取可能会产生一个与第一次不同的值。）

在处理特殊内存时，必须保留看似冗余访问和无用存储的事实，顺便说明了为什么 `std::atomic` 不适合这种场景。编译器被允许消除对 `std::atomic` 的冗余操作。

```c++
std::atomic<int> x;
auto y = x;                             //错误
y = x;                                  //错误
```

这是因为 `std::atomic` 类型的拷贝操作是被删除的（参见 Item 11）。因为有个很好的理由删除。想象一下如果 `y` 使用 `x` 来初始化会发生什么。因为 `x` 是 `std::atomic` 类型，`y` 的类型被推导为 `std::atomic`（参见 Item 2）。我之前说了 `std::atomic` 最好的特性之一就是所有成员函数都是原子性的，但是为了使从 `x` 拷贝初始化 `y` 的过程是原子性的，编译器不得不生成代码，把读取 `x` 和写入 `y` 放在一个单独的原子性操作中。硬件通常无法做到这一点，因此 `std::atomic` 不支持拷贝构造。出于同样的原因，拷贝赋值也被删除了，这也是为什么从 `x` 赋值给 `y` 也编译失败。（移动操作在 `std::atomic` 没有显式声明，因此根据 Item 17中描述的规则来看，`std::atomic` 不支持移动构造和移动赋值）。

可以将 `x` 的值传递给 `y`，但是需要使用 `std::atomic` 的 `load`和 `store` 成员函数。`load` 函数原子性地读取，`store` 原子性地写入。

```c++
std::atomic<int> y(x.load());           //读x
y.store(x.load());                      //再次读x
```

这可以编译，读取 `x`（通过 `x.load()`）是与初始化或者存储到 `y` 相独立的函数，这个事实清楚地表明没理由期待上面的任何一个语句会在单独的原子性的操作中整体执行。

- `std::atomic` 用在并发编程中，对访问特殊内存没用。
- `volatile` 用于访问特殊内存，对并发编程没用。

因为 `std::atomic` 和 `volatile` 用于不同的目的，所以可以结合起来使用。

最后一点，一些开发者在即使不必要时也尤其喜欢使用 `std::atomic` 的 `load` 和 `store` 函数，因为这在代码中显式表明了这个变量不“正常”。强调这一事实并非没有道理。因为访问 `std::atomic` 确实会比 non-`std::atomic` 更慢一些，我们也看到了 `std::atomic` 会阻止编译器对代码执行一些特定的，本应被允许的顺序重排。调用 `load` 和 `store` 可以帮助识别潜在的可扩展性瓶颈。从正确性的角度来看，没有看到在一个变量上调用 `store` 来与其他线程进行通信（比如用个 flag 表示数据的可用性）可能意味着该变量在声明时本应使用而没有使用 `std::atomic`。

这更多是习惯问题，但是，一定要知道 `atomic` 和 `volatile` 的巨大不同。

**请记住：**

- `std::atomic` 用于在不使用互斥锁情况下，来使变量被多个线程访问的情况。是用来编写并发程序的一个工具。
- `volatile` 用在读取和写入不应被优化掉的内存上。是用来处理特殊内存的一个工具。
